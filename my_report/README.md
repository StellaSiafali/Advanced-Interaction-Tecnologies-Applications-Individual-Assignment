# Lesson: Advanced Interaction Technologies & Applications

### First and Last Name: Stella Siafali
### University Registration Number: dpsd19118
### GitHub Personal Profile: StellaSiafali
### Advanced Interaction Tecnologies & Applications Github Personal Repository:https://github.com/StellaSiafali/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment

# Introduction

#### Στο παραπάνω μάθημα γενικότερα,γίνετε μία εισαγωγή θεμάτων σχεδιασμού, ανάπτυξης, εφαρμογής και αξιολόγησης advanced user interfaces και natural user interfaces, NUIs. 


# Summary


# 1st Deliverable 

## ***1. Video Capture*** (:camera:)
  
#### Για την εκτέλεση του 1ου παραδοτέου εργάστηκα ως εξής: αρχικά συνδέθηκα στο λογαριασμό μου στο GitHub, διάβασα ώστε να κατανοήσω πλήρως τα ζητούμενα και συνέχισα στα στάδια προκειμένου να υλοποιήσει το παραδοτέο. Για να καταφέρω να το τρέξω κατέβασα την βιβλιοθήκη "Video Library for Processing 3 2.0 The Processing Foundation" στο Processing, έπειτα για το κώδικα που χρησιμοποίησα βοηθήθηκα από το Εxample 16-1 (http://learningprocessing.com/examples/chp16/example-16-01-Capture). Ο κώδικας δεν μου παρουσίαζε κάποιο σφάλμα και έτσι η εκτέλεση αυτού του παρεδοτέο ολοκληρώθηκε ομαλλά.

Παρακάτω παρουσιάζεται ένα screenshot που μου εμφανίζεται καθώς κάνω run τον κώδικα μου:
![1st screen](https://user-images.githubusercontent.com/100956284/199837537-f6450cf6-89ae-4b56-8ce9-113d014d91c0.png)

## ***2. Recorded Video*** (:video_camera:) 

#### Συνεχίζοντας στο παραδοτέο 2 μελέτησα το Example 16-4 και Example 16-5 από το (http://learningprocessing.com/). Μου ζητήθηκα να χρησιμοποιήσω ένα video λίγων δευτερολέπτων, οπότε έπειτα από μία ολιγόλεπτη αναζήτηση στο YouTube κατέβασα ένα video 12sec. Επεξεργάστηκα τον κώδικα μου με τέτοιο τρόπο ώστε καθώς τοποθετώ το ποντίκι πάνω στο video και το κινώ, (που παίζει σε επανάληψη), θα αυξομειώνεται η ταχύτητα του. 

Το screenshot που εμφανίζεται παρακάτω παρουσιάζει το video που επέλεξα (δεν έχει τόσο καλή ανάλυση):disappointed::
![2st screen](https://user-images.githubusercontent.com/100956284/199840692-8bfd51de-64d8-4c39-996e-5baf5e864a41.png)

## ***3. QR Code*** (:checkered_flag:)

#### Για την εκτέλεση του 3ου παραδοτέου κατέβασα την βιβλιοθήκη "QRCode 0.3a Daniel Shiffman" από την διεύθυνση συνδέσμου στο Processing QRCode Library. Μου ζητήθηκε να δημιουργήσω το δικό μου QR code, το οποίο έκανα χρησιμοποιώντας αυτό το on-line side https://www.qrcode-monkey.com/. Το QR code που δημιούργησα το επεξεργάστηκα έτσι ώστε να οδηγεί σκανάρωντας το στο λογαργασμό μου GitHub μου. Μελέτησα το σωστό λινγκ που μας δώθηκε και έπειτα από πολλές προσπάθειες κατάφερα να εμφανίζεται το QR code μου στην οθόνη και να οδηγεί στον λογαργιασμό του GitHub μου, όταν τρέχω τον κώδικα.

Το παρακάτω στιγμιότυπο αποτυπώνει την στιγμή που τρέχω τον κώδικα εμφανίζεται το QR μου και οδηγεί στον λογαριασμό του GitHub μου:
![5st screen correct](https://user-images.githubusercontent.com/100956284/199843553-ceb08014-8448-4a6f-a722-df308218a4af.png)

## 4. ***QR Code - Camera Read*** (:camera::checkered_flag:)

#### Συνεχίζοντας στο παραδοτέα 4 εργάστηκα όπως διάβασα τις οδηγίες. Μελέτησα δηλαδή το έτοιμο παράδειγμα QRCodeExample, το οποίο βρισκόταν στην βιβλιοθήκη, την οποία είχα κατεβάσει για το προηγούμενο παραδοτέο. Κάνοντας τις κατάλληλες αλλαγές προσάρμοσα τον κώδικα μου έτσι ώστε η κάμερα να διαβάζει το QRCode και στην συνέχεια να ανοίγει το URL της ιστοσελίδας μου στο GitHub. Τρέχοντας τον κώδικα σκανάροντας το QR code μου πάτησα το space και το πλήκτρο "Κ" για να εμφανιστεί η ιστοσελίδα μου. 

Τα screenshot παρουσιάζουν την διαδικασία που ακολουθώ καθώς τρέχω τον κώδικα. 

Το 1ο στιγμιότυπο δείχνει πως σκανάρω το QR code μου, το 2ο αποτυπώνει ότι έχει εντοπιστεί ηι στοσελίδα μου, ένω το 3ο στιγμιότυπο εμφανίζει την ιστοσελίδα μου:

|                                        |                                        |                                         |
|:-----------------------------------------:|:----------------------------------------------------:|:-------------------------------:|
|![5st screen a](https://user-images.githubusercontent.com/100956284/199855484-bf7e5889-fab4-4a37-99d6-39c3a2713f5e.png)|![5st screen b](https://user-images.githubusercontent.com/100956284/199855515-dffd2bc9-0aeb-4c2f-bdbd-18f2cf2251d7.png)|![5st screen c](https://user-images.githubusercontent.com/100956284/199855546-dc1c288f-d3af-4c81-8ef6-d71c0dc63d3f.png)"> | 

## 5. ***Augmented Reality*** (:sparkler:)

#### Τέλος, για το 5ο παραδοτέο εργάστηκα ως εξής: όπως μου ζητήθηκε μελέτησα το My first AR exploration with Processing, διάβασα τις οδηγίες χρήσης της βιβλιοθήκης NyARToolkit. Στην συνέχεια εγκατάστησα την τελευταία έκδοση της βιβλιοθήκης, επεξεργάστηκα το παράδειγμα simpleLite προκειμένου όταν τρέχω τον κώδικα μου και δείχνω την φωτογραφία να εμφανίζει στην οθόνη μια εικόνα της επιλόγης μου. 

Μου ζητήθηκε η αναγνώρισει της εικόνας από την κάμερα να πραγματοποιήται μέσω του marker Hiro, παρατήρησα πως η αναγνώριζε το marker Hiro εάν υπήρχε ένα πλαίσιο άσπρο γύρω από την εικόνα.

![5st correct](https://user-images.githubusercontent.com/100956284/200041322-edc68786-6dab-465d-979d-1ac3e2951098.png)

# 2nd Deliverable

## ***1. Background Removal***:black_circle:

#### Για την εκτέλση του 2ου παραδότεου εργάστηκα ως εξής: αρχικά διάβασα τις οδηγίες και εφόσον βεβαιώθηκα πως τις έχω κατανοήσει συνέχισα στην υλοποίησει του. Για το μέρος μου ζητήθηκε η αντικατάσταση του υπόβαθρου με ένα βίντεο. Άνοιξα το Example 16-12 το οποίο μελέτησα και εφάρμοσα ορισμένες αλλαγές στον κώδικα ώστε να ταιριάζουν στα δεδομένα που ήθελα. Επέλεξα να εμφανίζεται στο background video, χρησιμοποίησα το ίδιο video με αυτό το 1ο παραδοτέου. Για να καταφέρω να εισάγω το video πήγα στο Εxaple 16-4. Αφού έριξα μια ματία τον κώδικα θυμήθηκα πως λειτουργεί και το επόμενο βήμα ήταν το προσαρμόσω στα δικά μου δεδομένα. Έβαλα λοιπόν, στον κώδικα το όνομα από το video μου. Επεξεργάστηκα στις διαστάσεις (πλάτος, ύψος) με τέτοιο τρόπο προκειμένου να βεβαιωθώ ότι το video μου εμφανίζεται όπως το θέλω από πίσω μου. 

Παρακάτω σας παραδέτω ορισμένα screenshots, στα οποία εμφανίζομαι εγώ και το στιγμιότυπο του βίντεο. Δύστυχως το στιγμιότυπο από το βιντεάκι μου δεν εμφανίζεται πόλυ "καθαρά", διότι το πίσω background στο οποίο έκανα build τον κώδικα έχει πολλά αντικέιμενα αλλά και χρώματα.

|                                        |                                        |                                         |
|:-----------------------------------------:|:----------------------------------------------------:|:-------------------------------:|
|![](https://user-images.githubusercontent.com/100956284/207987044-8062fae8-c0aa-41a3-9251-be683a82bb49.png)|![](https://user-images.githubusercontent.com/100956284/207987082-184bdac1-c836-4b41-8482-a3d0ddd9a826.png)|![](https://user-images.githubusercontent.com/100956284/207987126-bc64cb4e-6ba9-4b77-86ad-05be69d1e82a.png)| 

## ***2. Motion Detection***:large_blue_circle:

#### Συνέχισα στην υλοποίηση του 2ου task. Ακολουθώντας τις οδηγίες μελέτησα το Example 16-11 και το Example 16-13. Στην συνέχεια προσπάθησα να υλοποιήσω το Exercise 16-7, το επεξεργάστηκα, εφαρμόζοντας και πάλι αλλαγές στο κώδικα. Πιο συγκεκριμένα, άλλαξα το threshold (την ταχύτητα της μπάλας μου) έτσι ώστε η ταχύτητα της να είναι πιο αργή και να ακολουθεί τις κινήσεις μου πιο ομάλα, καθώς και το smooth, το fill (χρώμα) και το μέγεθος της.
Παρακάτω παρουσιάζοντα ορισμένα screenshots από κινήσεις μου που συνοδεύονται με την κίνηση της μπάλας μου. 

|                                        |                                        |                                         |
|:-----------------------------------------:|:----------------------------------------------------:|:-------------------------------:|
|![](https://user-images.githubusercontent.com/100956284/207986318-4ecab0bd-e970-4860-9c19-2be6c3ac78bd.png)|![](https://user-images.githubusercontent.com/100956284/207986357-9c7d1ff0-d701-43ad-b9bf-0c4ecd1853b8.png)|![](https://user-images.githubusercontent.com/100956284/207986378-165ed93b-9ea9-4be8-bb75-5c55be70f30a.png)| 

## ***3. Background Substraction - Library use***:white_circle:

#### Προχωρώντας στο task 3 εργάστηκα με τον εξής τρόπο: κατέβασα την βιβλιοθήκη OpenCV for Processing όπου άνοιξα το παράδειγμα BackgroundSubstraction, έτσι ακριβώς όπως με κατεύθυναν οι οδηγίες. Στην συνέχεια, επεξεργάστηκα το παράδειγμα ώστε να καταφέρω να υλοποιήσω τα ζητούμενα που μου ζητήθηκαν, διαγράφοντας από τον κώδικα το βίντεο και προσθέτοντας στην θέση του την κάμερα του υπολογιστή μου. Τέλος επέλεξα ένα χρώμα για το περίγραμμα (stroke) και το άλλαξα. 

Το αποτέλεσμα όπως φαίνεται και στα παρακάτω screenshots ήταν να μπορεί να ανιχνεύει τις κινήσεις μου, δημιουργώντας περιγράμματα του χρώματος που επέλεξα γύρω μου

|                                        |                                        |                                         |
|:-----------------------------------------:|:----------------------------------------------------:|:-------------------------------:|
|![](https://user-images.githubusercontent.com/100956284/207990445-36c89a3d-f4d8-4084-b292-0755df483d2c.png)|![](https://user-images.githubusercontent.com/100956284/207990472-63f4218c-45f1-4b6f-a84d-e2895903373c.png)


 ### :grey_question:Ερώτηση:grey_question:: 
 #### Ποια είναι τα πλεονεκτήματα και μειονεκτήματα της έτοιμης βιβλιοθήκης έναντι του κώδικα από το πρώτο ερώτημα;
 ### :pencil2:Απάντηση:pencil2:: 
 #### Με την χρήση της συγκεκριμένης βιβλιοθήκης επιτυνχάνεται η αναγνώριση από τις κινήσεις του σώματος, η διαδικασία γίνεται γρηγορότερη και ευκολότερη. Επιπλέον, θεωρείται κατάλληλη σε εφαρμογές όπου υπάρχει κάμερα σε φυσικό χώρο, καθώς επίσης είναι ικάνη να εντοπίσει αντικείμενα μιας εικόνας. Όμως, για να μπορέσω να την χρησιμοποιήσω θα πρέπει να την εγκαταστήσω και για να καταφέρει να λειτουργήσει σωστά είναι απαραίτητο να υπάρχει σωστός/καλός φωστισμός. Δεν χρησιμοποιήσαμε τον κώδικα του πρώτου ερωτήματος γιατί θα έπρεπε να γίνει σύκριση του κάθε pixel με το προηγούμενο του το οποίο απιτεί περισσότερο χρόνο.

## ***4. Object Tracking***:red_circle:

#### Ολοκληρώντας το 2ο παραδοτεό για το 4ο task μελέτησα και επεξεργάστηκα το Exercise 16-5. Στην κλάση του snake άλλαξα το πως εμφανίζεται οι κύκλοι και η διαδρομή εμφανίζοντας του κάθε αντικειμένου. Χρησιμοποιόντας μία εντολή στον κώδικα μου η κάμερα εντοπίζει το αντικείμενο που εμφανίζω μπροστά της και εμφανίζει το χρώμα του αλλά και πίσω από αυτό μία σειρά παρόμοιων χρωμάτων.

Screenshots υλοποίησς του 4ου task:

|                                        |                                        |                                         |
|:-----------------------------------------:|:----------------------------------------------------:|:-------------------------------:|
|![](https://user-images.githubusercontent.com/100956284/207995001-9fc41cda-83ea-4adf-a21d-8d722597c3c4.png)|![](https://user-images.githubusercontent.com/100956284/207995029-907ba6c2-1a46-4a04-b3ce-c7d10fd6d8ef.png)|
![](https://user-images.githubusercontent.com/100956284/207995049-0fe6d85d-995c-4841-88c9-b753eb2b5cbc.png)|![](https://user-images.githubusercontent.com/100956284/207995060-c4d56a77-dee6-4d87-a5f6-179a74d00cab.png)|
![](https://user-images.githubusercontent.com/100956284/207995129-68ffdef7-4a3d-40ae-a21e-ac1fccf8f13a.png)|![](https://user-images.githubusercontent.com/100956284/207995150-3feb178a-9c8b-4dd1-a96b-5fc43539431c.png)|

 ### :grey_question:Ερώτηση:grey_question:: 
 ####  Σε σχέση με το παραδοσιακό ποντίκι ποια είναι τα πλεονεκτήματα και ποια τα μειονεκτήματα αυτής της τεχνικής ελέγχου ενός ή περισσότερων σημείων σε μια οθόνη?
 ### :pencil2:Απάντηση:pencil2:: 
 #### Τα πλεονεκτήματα της τεχνικής ελένχου ενός ή περισσότερων σημείων σε μία οθόνη είναι ότι έχουμε εύκολη πρόσβαση, δεν απαιτείται input εξοπλιμός μόνο κάμερα καθώς επίσης είναι ικανή να διαχειρηστεί αντικείμενα από απόσταση. Τα μειονεκτήματα της είναι πως κολλάει και υπάρχουν φορές που ίσως δεν είανι τόσο αποτελεσματική.


# 3rd Deliverable 


# Bonus 


# Conclusions


# Sources
